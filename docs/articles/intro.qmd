---
title: great_tables
jupyter: python3
aliases:
  - ../index.html
html-table-processing: none
---

**`great_tables`** is a Python package for making publication-quality tables.

It provides robust functionality for customizing table structure and presentation, including:

* ðŸ”¬ Formatting for decimals, percentages, currencies, into various notations (e.g. scientific).
* ðŸŽ¶ Table titles, subtitles and notes.
* ä·– Clean presentation of row names and groupings.
* ðŸ“š Multi-level column spanners.

## Installing

```{.bash}
pip install great_tables
```

## Basic use

```{python}
from great_tables import GT, md
from great_tables.data import exibble, sp500

```

```{python}
gt_ex = GT(exibble.head(6))

gt_ex
```

### Formatting columns and adding a heading

```{python}
# Define the start and end dates for the data range
start_date = "2010-06-07"
end_date = "2010-06-14"

# Filter sp500 using pandas to date between start_date and end_date
sp500_mini = sp500[(sp500["date"] >= start_date) & (sp500["date"] <= end_date)]

# Create a gt table based on a subset of the `sp500` table data
(
    GT(data=sp500_mini)
    .tab_header(title="S&P 500", subtitle=f"{start_date} to {end_date}")
    .fmt_currency(columns=["open", "high", "low", "close"])
    .fmt_date(columns="date", date_style="wd_m_day_year")
    .fmt_integer(columns="volume")
)
```


### Titles and notes

```{python}
(
    gt_ex.tab_header(
        title="An example table", subtitle=md("It's **pretty great**")
    ).tab_source_note("Source: great tables")
)
```

### Row names in the stub

```{python}
gt_ex = GT(exibble.head(6), rowname_col="row")

gt_ex
```

### Column spanners

```{python}
(
    gt_ex.tab_spanner("Basic", ["num", "char", "fctr"])
    .tab_spanner("Dates", ["date", "datetime"])
    .tab_spanner("Misc", ["currency", "row", "group"])
)
```

## Anatomy of a table

The **`great_tables`** philosophy: we can construct a wide variety of useful tables with a cohesive set of table parts.
These include the *table header*, the *stub*, *column labels*/*spanner labels*, the *table body*, and the *table footer*.

![](/assets/gt_parts_of_a_table.svg)

It all begins with *table data* (which currently must be a pandas DataFrame). You then decide how to compose your table with the elements and formatting you need for the task at hand. The table is rendered either by printing it at the console, or by including it in a **Jupyter** notebook or a **Quarto** document.

![](/assets/gt_workflow_diagram.svg)

## Datasets

There are ten datasets available in provided by **`great_tables`**: `countrypops`, `sza`, `gtcars`, `sp500`, `pizzaplace`, `exibble`, `towny`, `metro`, `constants`, and `illness`.

<div align="center" style="padding-top:20px">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_countrypops.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_sza.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_gtcars.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_sp500.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_pizzaplace.svg" style="width:15%;">
</div>
<div align="center" style="padding-bottom:20px">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_exibble.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_towny.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_metro.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_constants.svg" style="width:15%;">
<img src="https://raw.githubusercontent.com/posit-dev/great-tables/main/images/dataset_illness.svg" style="width:15%;">
</div>

All of this tabular data is great for experimenting with the **`great_tables`** API and we make extensive use of these datasets in our documentation.
